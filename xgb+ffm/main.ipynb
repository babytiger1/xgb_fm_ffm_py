{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"../dataset/all/train.csv\"\n",
    "df = pd.read_csv(train_path,index_col=\"ID_code\")\n",
    "\n",
    "test_path = \"../dataset/all/test.csv\"\n",
    "df_eval = pd.read_csv(test_path,index_col=\"ID_code\")\n",
    "\n",
    "dfLabel = df['target']\n",
    "df = df.drop('target',axis=1)\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "###训练集\n",
    "train = df[msk]\n",
    "train_label = dfLabel[msk]\n",
    "###用来检测训练集的auc\n",
    "train_small_msk = np.random.rand(len(train)) < 0.2\n",
    "train_small = train[train_small_msk]\n",
    "train_small_label = train_label[train_small_msk]\n",
    "###测试集\n",
    "test = df[~msk]\n",
    "test_label = dfLabel[~msk]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0.1, learning_rate=0.01, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1000, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le = preprocessing.LabelEncoder()\n",
    "#dfLabel = le.fit(df['target']).transform(df['label'])\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "tree_model = XGBClassifier(\n",
    "silent=1 ,#设置成1则没有运行信息输出，最好是设置为0.是否在运行升级时打印消息。\n",
    "#nthread=4,# cpu 线程数 默认最大\n",
    "learning_rate= 0.01, # 如同学习率\n",
    "min_child_weight=1,\n",
    "nthread=4,  # 并行数\n",
    "# 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言\n",
    "#，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。\n",
    "#这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。\n",
    "max_depth=5, # 构建树的深度，越大越容易过拟合\n",
    "gamma=0.1,  # 树的叶子节点上作进一步分区所需的最小损失减少,越大越保守，一般0.1、0.2这样子，对叶节点个数的惩罚系数。\n",
    "subsample=1, # 随机采样训练样本 训练实例的子采样比\n",
    "max_delta_step=0,#最大增量步长，我们允许每个树的权重估计。\n",
    "colsample_bytree=1, # 生成树时进行的列采样\n",
    "reg_lambda=1,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "#reg_alpha=0, # L1 正则项参数\n",
    "#scale_pos_weight=1, #如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。平衡正负权重\n",
    "#objective= 'multi:softmax', #多分类的问题 指定学习任务和相应的学习目标\n",
    "#num_class=10, # 类别数，多分类与 multisoftmax 并用\n",
    "n_estimators=100, #树的个数\n",
    "seed=1000 #随机种子\n",
    "#eval_metric= 'auc'\n",
    ")\n",
    "\n",
    "tree_model.fit(train,train_label )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7172\n",
      "ACC: 0.8989\n",
      "Recall: 0.0005\n",
      "F1-score: 0.0010\n",
      "Precesion: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def eval_res(test_label,preds):\n",
    "\ty = test_label\n",
    "\tscores = preds\n",
    "\ty_pred = (scores >= 0.5)*1\n",
    "\tprint('AUC: %.4f' % metrics.roc_auc_score(y,scores))\n",
    "\tprint('ACC: %.4f' % metrics.accuracy_score(y,y_pred))\n",
    "\tprint('Recall: %.4f' % metrics.recall_score(y,y_pred))\n",
    "\tprint('F1-score: %.4f' %metrics.f1_score(y,y_pred))\n",
    "\tprint('Precesion: %.4f' %metrics.precision_score(y,y_pred))\n",
    "    \n",
    "preds = tree_model.predict_proba(test)   \n",
    "eval_res(test_label,preds[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58, 58, 57, ..., 56, 61, 49],\n",
       "       [58, 58, 57, ..., 56, 61, 49],\n",
       "       [36, 35, 44, ..., 56, 45, 49],\n",
       "       ...,\n",
       "       [51, 51, 57, ..., 42, 61, 58],\n",
       "       [58, 58, 57, ..., 41, 60, 49],\n",
       "       [51, 51, 57, ..., 41, 61, 49]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh = tree_model.apply(train)\n",
    "tm_enc = OneHotEncoder(categories='auto',sparse = 'false')\n",
    "res_date = tm_enc.fit(train_oh).transform(train_oh)\n",
    "all_cat = tm_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n"
     ]
    }
   ],
   "source": [
    "#  y field_1:index_1:value_1 field_2:index_2:value_2   ...\n",
    "### 转换train 数据集合 \n",
    "all_cat = tm_enc.categories_\n",
    "\n",
    "def convert2ffm(lines):\n",
    "    str_res=\"\"\n",
    "    for item_ind in range(len(lines)):\n",
    "        cats = all_cat[item_ind]\n",
    "        try:\n",
    "            index = cats.tolist().index(lines[item_ind])+1\n",
    "        except:\n",
    "            index = 0\n",
    "        str_one= \" \" + str(item_ind) + \":\" + str(index) + \":1\"\n",
    "        str_res+=str_one\n",
    "    return str_res  \n",
    "\n",
    "count=0\n",
    "with open(\"train_ffm.libffm\",\"w\") as wrop:\n",
    "    for label , lines in zip(train_label,train_oh):  \n",
    "        if count%1000 == 0:\n",
    "            print count\n",
    "        res_format = str(label) + convert2ffm(lines) + \"\\n\"\n",
    "        wrop.write(res_format) \n",
    "        count = count+1\n",
    "wrop.close()  \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oh = tree_model.apply(test)\n",
    "test_date = tm_enc.transform(test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "### 转换test数据集合 \n",
    "all_cat = tm_enc.categories_\n",
    "def convert2ffm(lines):\n",
    "    str_res=\"\"\n",
    "    for item_ind in range(len(lines)):\n",
    "        cats = all_cat[item_ind]\n",
    "        try:\n",
    "            index = cats.tolist().index(lines[item_ind])+1\n",
    "        except:\n",
    "            index = 0\n",
    "        str_one= \" \" + str(item_ind) + \":\" + str(index) + \":1\"\n",
    "        str_res+=str_one\n",
    "    return str_res  \n",
    "\n",
    "count=0\n",
    "with open(\"test_ffm.libffm\",\"w\") as wrop:\n",
    "    for label , lines in zip(test_label,test_oh):  \n",
    "        if count%1000 == 0:\n",
    "            print count\n",
    "        res_format = str(label) + convert2ffm(lines) + \"\\n\"\n",
    "        wrop.write(res_format)\n",
    "        count = count+1\n",
    "wrop.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "###### 如果加入dense vector会强烈降低auc\n",
    "# train_add = np.hstack((train.values,res_date.toarray()))\n",
    "# test_add = np.hstack((test.values,test_date.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl\n",
    "\n",
    "ffm_model1 = xl.create_ffm() \n",
    "ffm_model1.setTrain(\"train_ffm.libffm\") \n",
    "ffm_model1.setValidate(\"test_ffm.libffm\")\n",
    "\n",
    "ffm_model2 = xl.create_ffm() \n",
    "ffm_model2.setTrain(\"train_ffm.libffm\") \n",
    "ffm_model2.setValidate(\"test_ffm.libffm\")\n",
    "\n",
    "ffm_model3 = xl.create_ffm() \n",
    "ffm_model3.setTrain(\"train_ffm.libffm\") \n",
    "ffm_model3.setValidate(\"test_ffm.libffm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7452\n",
      "ACC: 0.9010\n",
      "Recall: 0.0686\n",
      "F1-score: 0.1230\n",
      "Precesion: 0.5915\n"
     ]
    }
   ],
   "source": [
    "import xlearn as xl\n",
    "ffm_model1 = xl.create_ffm() \n",
    "ffm_model1.setTrain(\"train_ffm.libffm\") \n",
    "ffm_model1.setValidate(\"test_ffm.libffm\")\n",
    "\n",
    "param1 = {'task':'binary', 'lr':0.1, 'lambda':0.002,'epoch':20,'opt':'ftrl'}\n",
    "ffm_model1.fit(param1, \"model1.out\")\n",
    "\n",
    "ffm_model1.setSigmoid()\n",
    "ffm_model1.setTest(\"test_ffm.libffm\")\n",
    "ffm_model1.predict(\"model1.out\", \"output1.txt\")\n",
    "preds = numpy.loadtxt('output1.txt')\n",
    "eval_res(test_label,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7439\n",
      "ACC: 0.9004\n",
      "Recall: 0.0716\n",
      "F1-score: 0.1269\n",
      "Precesion: 0.5598\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def eval_res(test_label,preds):\n",
    "\ty = test_label\n",
    "\tscores = preds\n",
    "\ty_pred = (scores >= 0.5)*1\n",
    "\tprint('AUC: %.4f' % metrics.roc_auc_score(y,scores))\n",
    "\tprint('ACC: %.4f' % metrics.accuracy_score(y,y_pred))\n",
    "\tprint('Recall: %.4f' % metrics.recall_score(y,y_pred))\n",
    "\tprint('F1-score: %.4f' %metrics.f1_score(y,y_pred))\n",
    "\tprint('Precesion: %.4f' %metrics.precision_score(y,y_pred))\n",
    "    \n",
    "ffm_model1.setSigmoid()\n",
    "ffm_model1.setTest(\"test_ffm.libffm\")\n",
    "ffm_model1.predict(\"model1.out\", \"output1.txt\")\n",
    "preds = numpy.loadtxt('output1.txt')\n",
    "eval_res(test_label,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = {'task':'binary', 'lr':0.1, 'lambda':0.002,'epoch':20,'k':8,'opt':'sgd'}\n",
    "param2 = {'task':'binary', 'lr':0.1, 'lambda':0.002,'epoch':20,'k':8,'opt':'adagrad'}\n",
    "param3 = {'task':'binary', 'lr':0.1, 'lambda':0.002,'epoch':20,'k':8,'opt':'ftrl'}\n",
    "\n",
    "\n",
    "# Train model\n",
    "ffm_model1.fit(param1, \"model1/model1.out\")\n",
    "ffm_model2.fit(param2, \"model2/model2.out\")\n",
    "ffm_model3.fit(param3, \"model3/model3.out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffm_model.setSign()\n",
    "# ffm_model.setTest(\"bb.libsvm\")\n",
    "# ffm_model.predict(\"model.out\", \"output_label.txt\")\n",
    "\n",
    "ffm_model1.setSigmoid()\n",
    "ffm_model1.setTest(\"test_ffm.libffm\")\n",
    "ffm_model1.predict(\"model1/model1.out\", \"model1/output1.txt\")\n",
    "\n",
    "ffm_model2.setSigmoid()\n",
    "ffm_model2.setTest(\"test_ffm.libffm\")\n",
    "ffm_model2.predict(\"model2/model2.out\", \"model2/output2.txt\")\n",
    "\n",
    "ffm_model3.setSigmoid()\n",
    "ffm_model3.setTest(\"test_ffm.libffm\")\n",
    "ffm_model3.predict(\"model3/model3.out\", \"model3/output3.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "preds = numpy.loadtxt('model1/output1.txt')\n",
    "eval_res(test_label,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7474\n",
      "ACC: 0.9041\n",
      "Recall: 0.0782\n",
      "F1-score: 0.1386\n",
      "Precesion: 0.6063\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "preds = numpy.loadtxt('model2/output2.txt')\n",
    "eval_res(test_label,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7521\n",
      "ACC: 0.9037\n",
      "Recall: 0.0879\n",
      "F1-score: 0.1525\n",
      "Precesion: 0.5748\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "preds = numpy.loadtxt('model3/output3.txt')\n",
    "eval_res(test_label,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
